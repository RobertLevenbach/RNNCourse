{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ipython: 7.6.1\n",
      "Numpy: 1.16.4\n",
      "Scipy: 1.2.1\n",
      "Matplotlib: 3.1.0\n",
      "Sklearn: 0.21.2\n",
      "Seaborn: 0.9.0\n",
      "Pandas: 0.24.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras: 2.0.5\n",
      "Tensorflow: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import IPython\n",
    "print('Ipython:', IPython.__version__)\n",
    "import numpy\n",
    "print(\"Numpy:\", numpy.__version__)\n",
    "import scipy\n",
    "print(\"Scipy:\", scipy.__version__)\n",
    "import matplotlib\n",
    "print(\"Matplotlib:\", matplotlib.__version__)\n",
    "import sklearn\n",
    "print(\"Sklearn:\", sklearn.__version__)\n",
    "import seaborn\n",
    "print(\"Seaborn:\", seaborn.__version__)\n",
    "import pandas\n",
    "print(\"Pandas:\", pandas.__version__)\n",
    "import keras\n",
    "print(\"Keras:\", keras.__version__)\n",
    "import tensorflow\n",
    "print(\"Tensorflow:\", tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random number seed for initializing> you can reproduce results with this seed state\n",
    "np.random.seed(10)\n",
    "\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "#RNN structures\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Activation, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#dataset\n",
    "#mnist dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "Timesteps = 28\n",
    "#image size is 28x28\n",
    "inputsize= 28  \n",
    "#number of classes\n",
    "noc= 10\n",
    "# 50 pictures per time/batch\n",
    "batch_size = 50\n",
    "#batchindex\n",
    "batchindex=0\n",
    "#outputsize\n",
    "output_size=10\n",
    "#cellsize\n",
    "cell_size=50\n",
    "#learning rate\n",
    "lr=0.001\n",
    "\n",
    "#load dataset> divide in train and test set\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#preprocess data so it works in tensorflow and keras\n",
    "#XVALUES: /255 to normalize (amount of pixels)\n",
    "X_train = X_train.reshape(-1,28,28)/255.\n",
    "X_test = X_test.reshape(-1,28,28)/255.\n",
    "\n",
    "#YVALUES: one-to-one  using np.utils, num_classes is amount of classes\n",
    "y_train= np_utils.to_categorical(y_train, num_classes=noc)\n",
    "y_test= np_utils.to_categorical(y_test, num_classes=noc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:431: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1190: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:699: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2751: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(batch_input_shape=(None, 28,..., unroll=True, units=50)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Create RNN in keras\n",
    "\n",
    "#need model> sequence model\n",
    "model = Sequential()\n",
    "#add(structure(batch_input_shape, timesteps), output dimensions, unroll))\n",
    "# batch input shape= we are using tensorflow back-end> you have to put the none in the inputshape!\n",
    "# output_dim = output size\n",
    "# we are unrolling the simple RNN in time> 28 timesteps, so 28 times unrolling sample SimpleRNN\n",
    "model.add(SimpleRNN(batch_input_shape=(None,Timesteps, inputsize), output_dim=cell_size, unroll=True ))\n",
    "#add Dense layer= 10 predictions\n",
    "model.add(Dense(output_size))\n",
    "#add activation> famous softmax used\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#use optimizer with learning rate\n",
    "adam = Adam(lr)\n",
    "#compile it with categorical crossentropy loss function (10 numbers!)\n",
    "# track more metrics (here accuracy)\n",
    "model.compile(optimizer= adam, loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now train model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
